# Multi-container approach - more reliable but uses more resources
# Use this if you have issues with the single container approach

services:
  # Node.js API Service
  nodejs-api:
    build:
      context: .
      dockerfile: Dockerfile.multi
    container_name: transcripts-nodejs
    ports:
      - "5685:5685"
    environment:
      - NODE_ENV=production
      - PORT=5685
      - REDIS_URL=redis://redis:6379
      
      # Groq Cloud Configuration
      - GROQ_API_KEY=${GROQ_API_KEY}
      - GROQ_WHISPER_MODEL=${GROQ_WHISPER_MODEL:-whisper-large-v3-turbo}
      - GROQ_BASE_URL=${GROQ_BASE_URL:-https://api.groq.com/openai/v1}
      - GROQ_AUDIO_CODEC=${GROQ_AUDIO_CODEC:-aac}
      - GROQ_AUDIO_BITRATE_KBPS=${GROQ_AUDIO_BITRATE_KBPS:-32}
      - GROQ_CHUNK_SECONDS=${GROQ_CHUNK_SECONDS:-600}
      - GROQ_MAX_REQUEST_MB=${GROQ_MAX_REQUEST_MB:-15}
      
      # Local ASR Configuration
      - LOCAL_ASR_BASE_URL=http://python-asr:5686
      - LOCAL_ASR_MODEL=${LOCAL_ASR_MODEL:-base.en}
      - DEFAULT_MODEL_TYPE=${DEFAULT_MODEL_TYPE:-auto}
      
      # Service Configuration
      - MAX_SYNC_SECONDS=${MAX_SYNC_SECONDS:-900}
      
    volumes:
      - audio_data:/app/audio_file
    depends_on:
      - redis
      - python-asr
    restart: unless-stopped
    networks:
      - transcripts-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5685/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Python ASR Service
  python-asr:
    build:
      context: .
      dockerfile: Dockerfile.python
    container_name: transcripts-python
    ports:
      - "5686:5686"  # Expose for debugging (optional)
    volumes:
      - models_data:/app/models
      - huggingface_cache:/root/.cache/huggingface
    restart: unless-stopped
    networks:
      - transcripts-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5686/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

  # Redis Service
  redis:
    image: redis:7-alpine
    container_name: transcripts-redis
    ports:
      - "6381:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    command: redis-server --appendonly yes --maxmemory 256mb --maxmemory-policy allkeys-lru
    networks:
      - transcripts-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

volumes:
  audio_data:
    driver: local
  models_data:
    driver: local
  redis_data:
    driver: local
  huggingface_cache:
    driver: local

networks:
  transcripts-network:
    driver: bridge